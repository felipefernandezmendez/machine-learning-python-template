{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>name</th>\n",
                            "      <th>host_id</th>\n",
                            "      <th>host_name</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <th>last_review</th>\n",
                            "      <th>reviews_per_month</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Clean &amp; quiet apt home by the park</td>\n",
                            "      <td>2787</td>\n",
                            "      <td>John</td>\n",
                            "      <td>Brooklyn</td>\n",
                            "      <td>Kensington</td>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>Private room</td>\n",
                            "      <td>149</td>\n",
                            "      <td>1</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2018-10-19</td>\n",
                            "      <td>0.21</td>\n",
                            "      <td>6</td>\n",
                            "      <td>365</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Skylit Midtown Castle</td>\n",
                            "      <td>2845</td>\n",
                            "      <td>Jennifer</td>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>Midtown</td>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>225</td>\n",
                            "      <td>1</td>\n",
                            "      <td>45</td>\n",
                            "      <td>2019-05-21</td>\n",
                            "      <td>0.38</td>\n",
                            "      <td>2</td>\n",
                            "      <td>355</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
                            "      <td>4632</td>\n",
                            "      <td>Elisabeth</td>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>Harlem</td>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>Private room</td>\n",
                            "      <td>150</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Cozy Entire Floor of Brownstone</td>\n",
                            "      <td>4869</td>\n",
                            "      <td>LisaRoxanne</td>\n",
                            "      <td>Brooklyn</td>\n",
                            "      <td>Clinton Hill</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1</td>\n",
                            "      <td>270</td>\n",
                            "      <td>2019-07-05</td>\n",
                            "      <td>4.64</td>\n",
                            "      <td>1</td>\n",
                            "      <td>194</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
                            "      <td>7192</td>\n",
                            "      <td>Laura</td>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>East Harlem</td>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>80</td>\n",
                            "      <td>10</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2018-11-19</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                               name  host_id    host_name  \\\n",
                            "0                Clean & quiet apt home by the park     2787         John   \n",
                            "1                             Skylit Midtown Castle     2845     Jennifer   \n",
                            "2               THE VILLAGE OF HARLEM....NEW YORK !     4632    Elisabeth   \n",
                            "3                   Cozy Entire Floor of Brownstone     4869  LisaRoxanne   \n",
                            "4  Entire Apt: Spacious Studio/Loft by central park     7192        Laura   \n",
                            "\n",
                            "  neighbourhood_group neighbourhood  latitude  longitude        room_type  \\\n",
                            "0            Brooklyn    Kensington     40.65     -73.97     Private room   \n",
                            "1           Manhattan       Midtown     40.75     -73.98  Entire home/apt   \n",
                            "2           Manhattan        Harlem     40.81     -73.94     Private room   \n",
                            "3            Brooklyn  Clinton Hill     40.69     -73.96  Entire home/apt   \n",
                            "4           Manhattan   East Harlem     40.80     -73.94  Entire home/apt   \n",
                            "\n",
                            "   price  minimum_nights  number_of_reviews last_review  reviews_per_month  \\\n",
                            "0    149               1                  9  2018-10-19               0.21   \n",
                            "1    225               1                 45  2019-05-21               0.38   \n",
                            "2    150               3                  0         NaN                NaN   \n",
                            "3     89               1                270  2019-07-05               4.64   \n",
                            "4     80              10                  9  2018-11-19               0.10   \n",
                            "\n",
                            "   calculated_host_listings_count  availability_365  \n",
                            "0                               6               365  \n",
                            "1                               2               355  \n",
                            "2                               1               365  \n",
                            "3                               1               194  \n",
                            "4                               1                 0  "
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Your code here\n",
                "\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import statsmodels.api as sm\n",
                "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
                "from sklearn.model_selection import train_test_split\n",
                "import xgboost as xgb\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "import lightgbm as lgb\n",
                "from sklearn.model_selection import RandomizedSearchCV\n",
                "from skopt import BayesSearchCV\n",
                "from sklearn.metrics import *\n",
                "from sklearn.ensemble import BaggingRegressor\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import FunctionTransformer\n",
                "import joblib\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "ds1 = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/data-preprocessing-project-tutorial/main/AB_NYC_2019.csv\").iloc[:,1:]\n",
                "pd.set_option('display.precision', 2)\n",
                "pd.set_option('display.max_columns', None)\n",
                "\n",
                "ds1.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(48895, 15)"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds1.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 48895 entries, 0 to 48894\n",
                        "Data columns (total 15 columns):\n",
                        " #   Column                          Non-Null Count  Dtype  \n",
                        "---  ------                          --------------  -----  \n",
                        " 0   name                            48879 non-null  object \n",
                        " 1   host_id                         48895 non-null  int64  \n",
                        " 2   host_name                       48874 non-null  object \n",
                        " 3   neighbourhood_group             48895 non-null  object \n",
                        " 4   neighbourhood                   48895 non-null  object \n",
                        " 5   latitude                        48895 non-null  float64\n",
                        " 6   longitude                       48895 non-null  float64\n",
                        " 7   room_type                       48895 non-null  object \n",
                        " 8   price                           48895 non-null  int64  \n",
                        " 9   minimum_nights                  48895 non-null  int64  \n",
                        " 10  number_of_reviews               48895 non-null  int64  \n",
                        " 11  last_review                     38843 non-null  object \n",
                        " 12  reviews_per_month               38843 non-null  float64\n",
                        " 13  calculated_host_listings_count  48895 non-null  int64  \n",
                        " 14  availability_365                48895 non-null  int64  \n",
                        "dtypes: float64(3), int64(6), object(6)\n",
                        "memory usage: 5.6+ MB\n"
                    ]
                }
            ],
            "source": [
                "ds1.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0        2018-10-19\n",
                            "1        2019-05-21\n",
                            "2               NaN\n",
                            "3        2019-07-05\n",
                            "4        2018-11-19\n",
                            "            ...    \n",
                            "48890           NaN\n",
                            "48891           NaN\n",
                            "48892           NaN\n",
                            "48893           NaN\n",
                            "48894           NaN\n",
                            "Name: last_review, Length: 48895, dtype: object"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds1.loc[:,\"last_review\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(48895, 13)"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds = ds1.drop([\"last_review\",\"reviews_per_month\"], axis = 1)\n",
                "\n",
                "ds.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds.duplicated().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>host_id</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>count</th>\n",
                            "      <td>4.89e+04</td>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>48895.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>mean</th>\n",
                            "      <td>6.76e+07</td>\n",
                            "      <td>40.73</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>152.72</td>\n",
                            "      <td>7.03</td>\n",
                            "      <td>23.27</td>\n",
                            "      <td>7.14</td>\n",
                            "      <td>112.78</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>std</th>\n",
                            "      <td>7.86e+07</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>240.15</td>\n",
                            "      <td>20.51</td>\n",
                            "      <td>44.55</td>\n",
                            "      <td>32.95</td>\n",
                            "      <td>131.62</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>min</th>\n",
                            "      <td>2.44e+03</td>\n",
                            "      <td>40.50</td>\n",
                            "      <td>-74.24</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25%</th>\n",
                            "      <td>7.82e+06</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>69.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50%</th>\n",
                            "      <td>3.08e+07</td>\n",
                            "      <td>40.72</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>106.00</td>\n",
                            "      <td>3.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>45.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75%</th>\n",
                            "      <td>1.07e+08</td>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>175.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>24.00</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>227.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>max</th>\n",
                            "      <td>2.74e+08</td>\n",
                            "      <td>40.91</td>\n",
                            "      <td>-73.71</td>\n",
                            "      <td>10000.00</td>\n",
                            "      <td>1250.00</td>\n",
                            "      <td>629.00</td>\n",
                            "      <td>327.00</td>\n",
                            "      <td>365.00</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        host_id  latitude  longitude     price  minimum_nights  \\\n",
                            "count  4.89e+04  48895.00   48895.00  48895.00        48895.00   \n",
                            "mean   6.76e+07     40.73     -73.95    152.72            7.03   \n",
                            "std    7.86e+07      0.05       0.05    240.15           20.51   \n",
                            "min    2.44e+03     40.50     -74.24      0.00            1.00   \n",
                            "25%    7.82e+06     40.69     -73.98     69.00            1.00   \n",
                            "50%    3.08e+07     40.72     -73.96    106.00            3.00   \n",
                            "75%    1.07e+08     40.76     -73.94    175.00            5.00   \n",
                            "max    2.74e+08     40.91     -73.71  10000.00         1250.00   \n",
                            "\n",
                            "       number_of_reviews  calculated_host_listings_count  availability_365  \n",
                            "count           48895.00                        48895.00          48895.00  \n",
                            "mean               23.27                            7.14            112.78  \n",
                            "std                44.55                           32.95            131.62  \n",
                            "min                 0.00                            1.00              0.00  \n",
                            "25%                 1.00                            1.00              0.00  \n",
                            "50%                 5.00                            1.00             45.00  \n",
                            "75%                24.00                            2.00            227.00  \n",
                            "max               629.00                          327.00            365.00  "
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# elimino los valores menores a 0 para poder aplicar .log()\n",
                "ds = ds[ds[\"price\"] > 0]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1500x800 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "\n",
                "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
                "\n",
                "ax[0].hist(ds[\"price\"], bins=30, color=\"skyblue\", edgecolor = \"black\");\n",
                "ax[0].set_title('Histograma de PRICE')\n",
                "ax[0].set_xlabel('Precio')\n",
                "ax[0].set_ylabel('Frecuencia')\n",
                "\n",
                "\n",
                "ax[1].boxplot(ds['price'], vert=False);\n",
                "ax[1].set_title('Boxplot de PRICE')\n",
                "ax[1].set_xlabel('Precio')\n",
                "\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0        5.00\n",
                            "1        5.42\n",
                            "2        5.01\n",
                            "3        4.49\n",
                            "4        4.38\n",
                            "         ... \n",
                            "48890    4.25\n",
                            "48891    3.69\n",
                            "48892    4.74\n",
                            "48893    4.01\n",
                            "48894    4.50\n",
                            "Name: precio_log, Length: 48884, dtype: float64"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#\"La simetra de la varable que queremos predecir puede ser un problema...\"\n",
                "#Creacin de Columna con los precios transformados a escala logartmica\n",
                "\n",
                "ds[\"precio_log\"] = np.log(ds[\"price\"]);\n",
                "\n",
                "ds[\"precio_log\"] \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 48884 entries, 0 to 48894\n",
                        "Data columns (total 14 columns):\n",
                        " #   Column                          Non-Null Count  Dtype  \n",
                        "---  ------                          --------------  -----  \n",
                        " 0   name                            48868 non-null  object \n",
                        " 1   host_id                         48884 non-null  int64  \n",
                        " 2   host_name                       48863 non-null  object \n",
                        " 3   neighbourhood_group             48884 non-null  object \n",
                        " 4   neighbourhood                   48884 non-null  object \n",
                        " 5   latitude                        48884 non-null  float64\n",
                        " 6   longitude                       48884 non-null  float64\n",
                        " 7   room_type                       48884 non-null  object \n",
                        " 8   price                           48884 non-null  int64  \n",
                        " 9   minimum_nights                  48884 non-null  int64  \n",
                        " 10  number_of_reviews               48884 non-null  int64  \n",
                        " 11  calculated_host_listings_count  48884 non-null  int64  \n",
                        " 12  availability_365                48884 non-null  int64  \n",
                        " 13  precio_log                      48884 non-null  float64\n",
                        "dtypes: float64(3), int64(6), object(5)\n",
                        "memory usage: 5.6+ MB\n"
                    ]
                }
            ],
            "source": [
                "ds.info();"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x500 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
                "\n",
                "# Crear un histograma en el primer subplot\n",
                "ax[0].hist(ds['precio_log'], bins=20, color='skyblue', edgecolor='black')\n",
                "ax[0].set_title('Histograma de PRICE')\n",
                "ax[0].set_xlabel('Precio')\n",
                "ax[0].set_ylabel('Frecuencia')\n",
                "\n",
                "# Crear un boxplot en el segundo subplot\n",
                "ax[1].boxplot(ds['precio_log'], vert=False)\n",
                "ax[1].set_title('Boxplot de PRICE')\n",
                "ax[1].set_xlabel('Precio')\n",
                "\n",
                "# Mostrar la figura\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "name                              0.03\n",
                            "host_id                           0.00\n",
                            "host_name                         0.04\n",
                            "neighbourhood_group               0.00\n",
                            "neighbourhood                     0.00\n",
                            "latitude                          0.00\n",
                            "longitude                         0.00\n",
                            "room_type                         0.00\n",
                            "price                             0.00\n",
                            "minimum_nights                    0.00\n",
                            "number_of_reviews                 0.00\n",
                            "calculated_host_listings_count    0.00\n",
                            "availability_365                  0.00\n",
                            "precio_log                        0.00\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# % de valores nulos por columna.\n",
                "ds.isnull().mean()*100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Columnas con Valores Nulos: 2\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0         name\n",
                            "1    host_name\n",
                            "dtype: object"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "print(f\"Columnas con Valores Nulos: {ds.isnull().any(axis=0).sum()}\")\n",
                "columnas_con_nulos = ds.columns[ds.isnull().any()]\n",
                "pd.Series(columnas_con_nulos)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "37\n",
                        "0.07568938712053024\n",
                        "2\n"
                    ]
                }
            ],
            "source": [
                "#Filas con valores nules\n",
                "print(sum(ds.isnull().any(axis=1))) #??? No entiendo el axis en este caso si axis=0 son filas \n",
                "\n",
                "# % de filas con valores nulos -> Para tomar la desicin sobre Imputar los valores faltantes o Eliminar las filas con valores nulos.\n",
                "print(sum(ds.isnull().any(axis=1))/len(ds)*100)\n",
                "\n",
                "#Columnas con Valores Nulos\n",
                "print(ds.isnull().any().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 2500x1000 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import missingno as msno\n",
                "\n",
                "msno.matrix(ds);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.impute import KNNImputer\n",
                "\n",
                "#La asignacin de vecinos es teniendo en cuenta el orden original de DS o la frmula ordena las variables segn algn criterio ?\n",
                "\n",
                "# No hay valores faltaantes que sean numricos en el DS\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "name                               object\n",
                            "host_id                             int64\n",
                            "host_name                          object\n",
                            "neighbourhood_group                object\n",
                            "neighbourhood                      object\n",
                            "latitude                          float64\n",
                            "longitude                         float64\n",
                            "room_type                          object\n",
                            "price                               int64\n",
                            "minimum_nights                      int64\n",
                            "number_of_reviews                   int64\n",
                            "calculated_host_listings_count      int64\n",
                            "availability_365                    int64\n",
                            "precio_log                        float64\n",
                            "dtype: object"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# No estoy seguro si me tengo que cargar las variables tipo Object / string o si debo asignarles un equivalente numrico\n",
                "# Por lo pronto me las cargo para poder avanzar, si no no puedo calcular la distancia de cook.\n",
                "ds.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Elimino las columnas con valores no numricos\n",
                "ds_new = ds.drop([\"name\", \"host_name\", \"neighbourhood_group\", \"neighbourhood\", \"room_type\" ], axis=1, inplace=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "host_id                             int64\n",
                            "latitude                          float64\n",
                            "longitude                         float64\n",
                            "price                               int64\n",
                            "minimum_nights                      int64\n",
                            "number_of_reviews                   int64\n",
                            "calculated_host_listings_count      int64\n",
                            "availability_365                    int64\n",
                            "precio_log                        float64\n",
                            "dtype: object"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds_new.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bsqueda de Observaciones Influyentes (Valores Atpicos / Outliers) mediante la Distancia de Cook\n",
                "\n",
                "#Definicin de Variables: v. predictoras (X) / v. objetivo (Y)\n",
                "x = ds_new.drop([\"price\", \"precio_log\"], axis = 1)  # Variables Predictorias\n",
                "y= ds_new[\"precio_log\"]  # Variable Dependiente / Objetivo\n",
                "\n",
                "# Ajuste al Modelo:                # ValueError: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data). ?\n",
                "x = sm.add_constant(x)            # Debo eliminar las variables no Numrias ?\n",
                "modelo = sm.OLS(y, x).fit()\n",
                "\n",
                "\n",
                "# Instancia de la influencia y clculo de la Distancia de Cook\n",
                "distancia_cook = modelo.get_influence().cooks_distance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "#Plotear los resultados\n",
                "plt.scatter(x=ds_new.price, y=distancia_cook[0]) # No termino de entender por qu se pone el [0]\n",
                "plt.xlabel(\"Precio Normal\")\n",
                "plt.ylabel(\"Distancia de Cooks\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(array([ 2854,  5767, 17811, 44418]),)"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#posiciones en donde se detecta una distancia de cook extraordinaria \n",
                "np.where(distancia_cook[0] > 0.020)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "host_id                           2.20e+08\n",
                            "latitude                          4.08e+01\n",
                            "longitude                        -7.40e+01\n",
                            "price                             1.89e+02\n",
                            "minimum_nights                    2.90e+01\n",
                            "number_of_reviews                 0.00e+00\n",
                            "calculated_host_listings_count    3.27e+02\n",
                            "availability_365                  3.33e+02\n",
                            "precio_log                        5.24e+00\n",
                            "Name: 44419, dtype: float64"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds_new.iloc[44408]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Elimino las filas con estos valores outliers\n",
                "ds_new.drop([44408], axis=0, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Posiciones con Valores Atpicos\n",
                "ds_new = ds_new[ds_new.price < 9500]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index([], dtype='object')"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Winzorizacin -> solo variables numricas NO binaries\n",
                "#bsqueda de columnas con valores binarios \n",
                "\n",
                "col_binarias = ds_new[(ds_new == 0)|(ds_new == 1)].dropna(axis=1).columns\n",
                "col_binarias \n",
                "\n",
                "#No hay columnas con valores binarios\n",
                "\n",
                "#Esto detecta solo si hay 0 y/o 1 en la columna? O con que haya cualquier 0 o 1 ya lo detecta ?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "host_id                           37448\n",
                            "latitude                          19046\n",
                            "longitude                         14715\n",
                            "price                               671\n",
                            "minimum_nights                      109\n",
                            "number_of_reviews                   394\n",
                            "calculated_host_listings_count       47\n",
                            "availability_365                    366\n",
                            "precio_log                          671\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds_new.nunique()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "host_id                            1.21\n",
                            "latitude                           0.24\n",
                            "longitude                          1.28\n",
                            "price                             15.09\n",
                            "minimum_nights                    21.85\n",
                            "number_of_reviews                  3.69\n",
                            "calculated_host_listings_count     7.93\n",
                            "availability_365                   0.76\n",
                            "precio_log                         0.58\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds_new.apply(lambda x: x.skew())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Winzorizacin\n",
                "\n",
                "def winzorizar_columna(columna, lower, upper):\n",
                "    q1 = columna.quantile(lower)\n",
                "    q3 = columna.quantile(upper)\n",
                "    iqr_value = q3 - q1\n",
                "    lim_inf = q1 - 1.5 * iqr_value\n",
                "    lim_sup = q3 + 1.5 * iqr_value\n",
                "    columna = columna.clip(lower=lim_inf, upper=lim_sup)\n",
                "    \n",
                "    return columna\n",
                "\n",
                "\n",
                "for column in ds_new.columns:\n",
                "    ds_new[column] = winzorizar_columna(ds_new[column], 0.25, 0.75)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "host_id                           1.18\n",
                            "latitude                          0.24\n",
                            "longitude                         0.53\n",
                            "price                             1.02\n",
                            "minimum_nights                    1.29\n",
                            "number_of_reviews                 1.23\n",
                            "calculated_host_listings_count    1.15\n",
                            "availability_365                  0.76\n",
                            "precio_log                        0.32\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#El skew tras aplicar la Winzorizacin\n",
                "ds_new.apply(lambda x: x.skew())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>host_id</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>precio_log</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>count</th>\n",
                            "      <td>4.89e+04</td>\n",
                            "      <td>48877.00</td>\n",
                            "      <td>48877.00</td>\n",
                            "      <td>48877.00</td>\n",
                            "      <td>48877.00</td>\n",
                            "      <td>48877.00</td>\n",
                            "      <td>48877.00</td>\n",
                            "      <td>48877.00</td>\n",
                            "      <td>48877.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>mean</th>\n",
                            "      <td>6.74e+07</td>\n",
                            "      <td>40.73</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>132.99</td>\n",
                            "      <td>3.82</td>\n",
                            "      <td>15.67</td>\n",
                            "      <td>1.61</td>\n",
                            "      <td>112.78</td>\n",
                            "      <td>4.72</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>std</th>\n",
                            "      <td>7.80e+07</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>0.04</td>\n",
                            "      <td>83.49</td>\n",
                            "      <td>3.32</td>\n",
                            "      <td>20.35</td>\n",
                            "      <td>0.95</td>\n",
                            "      <td>131.63</td>\n",
                            "      <td>0.67</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>min</th>\n",
                            "      <td>2.44e+03</td>\n",
                            "      <td>40.58</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>10.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>2.84</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25%</th>\n",
                            "      <td>7.82e+06</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>69.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>4.23</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50%</th>\n",
                            "      <td>3.08e+07</td>\n",
                            "      <td>40.72</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>106.00</td>\n",
                            "      <td>3.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>45.00</td>\n",
                            "      <td>4.66</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75%</th>\n",
                            "      <td>1.07e+08</td>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>175.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>24.00</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>227.00</td>\n",
                            "      <td>5.16</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>max</th>\n",
                            "      <td>2.57e+08</td>\n",
                            "      <td>40.87</td>\n",
                            "      <td>-73.87</td>\n",
                            "      <td>334.00</td>\n",
                            "      <td>11.00</td>\n",
                            "      <td>58.50</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>365.00</td>\n",
                            "      <td>6.56</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        host_id  latitude  longitude     price  minimum_nights  \\\n",
                            "count  4.89e+04  48877.00   48877.00  48877.00        48877.00   \n",
                            "mean   6.74e+07     40.73     -73.95    132.99            3.82   \n",
                            "std    7.80e+07      0.05       0.04     83.49            3.32   \n",
                            "min    2.44e+03     40.58     -74.05     10.00            1.00   \n",
                            "25%    7.82e+06     40.69     -73.98     69.00            1.00   \n",
                            "50%    3.08e+07     40.72     -73.96    106.00            3.00   \n",
                            "75%    1.07e+08     40.76     -73.94    175.00            5.00   \n",
                            "max    2.57e+08     40.87     -73.87    334.00           11.00   \n",
                            "\n",
                            "       number_of_reviews  calculated_host_listings_count  availability_365  \\\n",
                            "count           48877.00                        48877.00          48877.00   \n",
                            "mean               15.67                            1.61            112.78   \n",
                            "std                20.35                            0.95            131.63   \n",
                            "min                 0.00                            1.00              0.00   \n",
                            "25%                 1.00                            1.00              0.00   \n",
                            "50%                 5.00                            1.00             45.00   \n",
                            "75%                24.00                            2.00            227.00   \n",
                            "max                58.50                            3.50            365.00   \n",
                            "\n",
                            "       precio_log  \n",
                            "count    48877.00  \n",
                            "mean         4.72  \n",
                            "std          0.67  \n",
                            "min          2.84  \n",
                            "25%          4.23  \n",
                            "50%          4.66  \n",
                            "75%          5.16  \n",
                            "max          6.56  "
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds_new.describe()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Clculo de variable adicionales ??\n",
                "#No se me ocurren"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style type=\"text/css\">\n",
                            "#T_37fe8_row0_col0, #T_37fe8_row1_col1, #T_37fe8_row2_col2, #T_37fe8_row3_col3, #T_37fe8_row4_col4, #T_37fe8_row5_col5, #T_37fe8_row6_col6, #T_37fe8_row7_col7, #T_37fe8_row8_col8 {\n",
                            "  background-color: #b40426;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row0_col1 {\n",
                            "  background-color: #485fd1;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row0_col2 {\n",
                            "  background-color: #b5cdfa;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row0_col3, #T_37fe8_row6_col0 {\n",
                            "  background-color: #96b7ff;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row0_col4, #T_37fe8_row3_col5 {\n",
                            "  background-color: #5f7fe8;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row0_col5 {\n",
                            "  background-color: #4f69d9;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row0_col6, #T_37fe8_row4_col6 {\n",
                            "  background-color: #8db0fe;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row0_col7, #T_37fe8_row6_col8 {\n",
                            "  background-color: #80a3fa;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row0_col8 {\n",
                            "  background-color: #93b5fe;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row1_col0, #T_37fe8_row2_col1, #T_37fe8_row5_col6 {\n",
                            "  background-color: #6384eb;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row1_col2 {\n",
                            "  background-color: #b2ccfb;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row1_col3, #T_37fe8_row6_col4 {\n",
                            "  background-color: #a6c4fe;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row1_col4, #T_37fe8_row5_col7 {\n",
                            "  background-color: #7b9ff9;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row1_col5 {\n",
                            "  background-color: #6a8bef;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row1_col6, #T_37fe8_row2_col7 {\n",
                            "  background-color: #5470de;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row1_col7, #T_37fe8_row2_col3, #T_37fe8_row2_col8, #T_37fe8_row4_col5, #T_37fe8_row5_col0, #T_37fe8_row5_col1, #T_37fe8_row5_col4, #T_37fe8_row8_col2, #T_37fe8_row8_col6 {\n",
                            "  background-color: #3b4cc0;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row1_col8, #T_37fe8_row5_col2, #T_37fe8_row6_col2 {\n",
                            "  background-color: #abc8fd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row2_col0, #T_37fe8_row3_col4, #T_37fe8_row6_col5 {\n",
                            "  background-color: #81a4fb;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row2_col4 {\n",
                            "  background-color: #506bda;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row2_col5 {\n",
                            "  background-color: #89acfd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row2_col6 {\n",
                            "  background-color: #6b8df0;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row3_col0, #T_37fe8_row3_col7 {\n",
                            "  background-color: #6180e9;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row3_col1 {\n",
                            "  background-color: #5977e3;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row3_col2 {\n",
                            "  background-color: #3f53c6;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row3_col6 {\n",
                            "  background-color: #445acc;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row3_col8 {\n",
                            "  background-color: #bd1f2d;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row4_col0, #T_37fe8_row4_col1 {\n",
                            "  background-color: #4b64d5;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row4_col2 {\n",
                            "  background-color: #799cf8;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row4_col3 {\n",
                            "  background-color: #a1c0ff;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row4_col7 {\n",
                            "  background-color: #6f92f3;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row4_col8 {\n",
                            "  background-color: #a2c1ff;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row5_col3 {\n",
                            "  background-color: #82a6fb;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row5_col8 {\n",
                            "  background-color: #8badfd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row6_col1 {\n",
                            "  background-color: #4257c9;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row6_col3 {\n",
                            "  background-color: #84a7fc;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row6_col7 {\n",
                            "  background-color: #c6d6f1;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row7_col0 {\n",
                            "  background-color: #9bbcff;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row7_col1 {\n",
                            "  background-color: #3e51c5;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row7_col2 {\n",
                            "  background-color: #aac7fd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row7_col3, #T_37fe8_row7_col8 {\n",
                            "  background-color: #afcafc;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row7_col4 {\n",
                            "  background-color: #9fbfff;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row7_col5 {\n",
                            "  background-color: #a9c6fd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row7_col6 {\n",
                            "  background-color: #d3dbe7;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_37fe8_row8_col0 {\n",
                            "  background-color: #5875e1;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row8_col1, #T_37fe8_row8_col7 {\n",
                            "  background-color: #5b7ae5;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row8_col3 {\n",
                            "  background-color: #be242e;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row8_col4 {\n",
                            "  background-color: #7ea1fa;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_37fe8_row8_col5 {\n",
                            "  background-color: #6485ec;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "</style>\n",
                            "<table id=\"T_37fe8\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th class=\"blank level0\" >&nbsp;</th>\n",
                            "      <th id=\"T_37fe8_level0_col0\" class=\"col_heading level0 col0\" >host_id</th>\n",
                            "      <th id=\"T_37fe8_level0_col1\" class=\"col_heading level0 col1\" >latitude</th>\n",
                            "      <th id=\"T_37fe8_level0_col2\" class=\"col_heading level0 col2\" >longitude</th>\n",
                            "      <th id=\"T_37fe8_level0_col3\" class=\"col_heading level0 col3\" >price</th>\n",
                            "      <th id=\"T_37fe8_level0_col4\" class=\"col_heading level0 col4\" >minimum_nights</th>\n",
                            "      <th id=\"T_37fe8_level0_col5\" class=\"col_heading level0 col5\" >number_of_reviews</th>\n",
                            "      <th id=\"T_37fe8_level0_col6\" class=\"col_heading level0 col6\" >calculated_host_listings_count</th>\n",
                            "      <th id=\"T_37fe8_level0_col7\" class=\"col_heading level0 col7\" >availability_365</th>\n",
                            "      <th id=\"T_37fe8_level0_col8\" class=\"col_heading level0 col8\" >precio_log</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row0\" class=\"row_heading level0 row0\" >host_id</th>\n",
                            "      <td id=\"T_37fe8_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
                            "      <td id=\"T_37fe8_row0_col1\" class=\"data row0 col1\" >0.020</td>\n",
                            "      <td id=\"T_37fe8_row0_col2\" class=\"data row0 col2\" >0.116</td>\n",
                            "      <td id=\"T_37fe8_row0_col3\" class=\"data row0 col3\" >0.013</td>\n",
                            "      <td id=\"T_37fe8_row0_col4\" class=\"data row0 col4\" >-0.064</td>\n",
                            "      <td id=\"T_37fe8_row0_col5\" class=\"data row0 col5\" >-0.127</td>\n",
                            "      <td id=\"T_37fe8_row0_col6\" class=\"data row0 col6\" >0.183</td>\n",
                            "      <td id=\"T_37fe8_row0_col7\" class=\"data row0 col7\" >0.203</td>\n",
                            "      <td id=\"T_37fe8_row0_col8\" class=\"data row0 col8\" >-0.019</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row1\" class=\"row_heading level0 row1\" >latitude</th>\n",
                            "      <td id=\"T_37fe8_row1_col0\" class=\"data row1 col0\" >0.020</td>\n",
                            "      <td id=\"T_37fe8_row1_col1\" class=\"data row1 col1\" >1.000</td>\n",
                            "      <td id=\"T_37fe8_row1_col2\" class=\"data row1 col2\" >0.110</td>\n",
                            "      <td id=\"T_37fe8_row1_col3\" class=\"data row1 col3\" >0.075</td>\n",
                            "      <td id=\"T_37fe8_row1_col4\" class=\"data row1 col4\" >0.031</td>\n",
                            "      <td id=\"T_37fe8_row1_col5\" class=\"data row1 col5\" >-0.026</td>\n",
                            "      <td id=\"T_37fe8_row1_col6\" class=\"data row1 col6\" >-0.001</td>\n",
                            "      <td id=\"T_37fe8_row1_col7\" class=\"data row1 col7\" >-0.011</td>\n",
                            "      <td id=\"T_37fe8_row1_col8\" class=\"data row1 col8\" >0.083</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row2\" class=\"row_heading level0 row2\" >longitude</th>\n",
                            "      <td id=\"T_37fe8_row2_col0\" class=\"data row2 col0\" >0.116</td>\n",
                            "      <td id=\"T_37fe8_row2_col1\" class=\"data row2 col1\" >0.110</td>\n",
                            "      <td id=\"T_37fe8_row2_col2\" class=\"data row2 col2\" >1.000</td>\n",
                            "      <td id=\"T_37fe8_row2_col3\" class=\"data row2 col3\" >-0.365</td>\n",
                            "      <td id=\"T_37fe8_row2_col4\" class=\"data row2 col4\" >-0.121</td>\n",
                            "      <td id=\"T_37fe8_row2_col5\" class=\"data row2 col5\" >0.081</td>\n",
                            "      <td id=\"T_37fe8_row2_col6\" class=\"data row2 col6\" >0.078</td>\n",
                            "      <td id=\"T_37fe8_row2_col7\" class=\"data row2 col7\" >0.073</td>\n",
                            "      <td id=\"T_37fe8_row2_col8\" class=\"data row2 col8\" >-0.388</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row3\" class=\"row_heading level0 row3\" >price</th>\n",
                            "      <td id=\"T_37fe8_row3_col0\" class=\"data row3 col0\" >0.013</td>\n",
                            "      <td id=\"T_37fe8_row3_col1\" class=\"data row3 col1\" >0.075</td>\n",
                            "      <td id=\"T_37fe8_row3_col2\" class=\"data row3 col2\" >-0.365</td>\n",
                            "      <td id=\"T_37fe8_row3_col3\" class=\"data row3 col3\" >1.000</td>\n",
                            "      <td id=\"T_37fe8_row3_col4\" class=\"data row3 col4\" >0.053</td>\n",
                            "      <td id=\"T_37fe8_row3_col5\" class=\"data row3 col5\" >-0.066</td>\n",
                            "      <td id=\"T_37fe8_row3_col6\" class=\"data row3 col6\" >-0.056</td>\n",
                            "      <td id=\"T_37fe8_row3_col7\" class=\"data row3 col7\" >0.113</td>\n",
                            "      <td id=\"T_37fe8_row3_col8\" class=\"data row3 col8\" >0.962</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row4\" class=\"row_heading level0 row4\" >minimum_nights</th>\n",
                            "      <td id=\"T_37fe8_row4_col0\" class=\"data row4 col0\" >-0.064</td>\n",
                            "      <td id=\"T_37fe8_row4_col1\" class=\"data row4 col1\" >0.031</td>\n",
                            "      <td id=\"T_37fe8_row4_col2\" class=\"data row4 col2\" >-0.121</td>\n",
                            "      <td id=\"T_37fe8_row4_col3\" class=\"data row4 col3\" >0.053</td>\n",
                            "      <td id=\"T_37fe8_row4_col4\" class=\"data row4 col4\" >1.000</td>\n",
                            "      <td id=\"T_37fe8_row4_col5\" class=\"data row4 col5\" >-0.210</td>\n",
                            "      <td id=\"T_37fe8_row4_col6\" class=\"data row4 col6\" >0.182</td>\n",
                            "      <td id=\"T_37fe8_row4_col7\" class=\"data row4 col7\" >0.157</td>\n",
                            "      <td id=\"T_37fe8_row4_col8\" class=\"data row4 col8\" >0.042</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row5\" class=\"row_heading level0 row5\" >number_of_reviews</th>\n",
                            "      <td id=\"T_37fe8_row5_col0\" class=\"data row5 col0\" >-0.127</td>\n",
                            "      <td id=\"T_37fe8_row5_col1\" class=\"data row5 col1\" >-0.026</td>\n",
                            "      <td id=\"T_37fe8_row5_col2\" class=\"data row5 col2\" >0.081</td>\n",
                            "      <td id=\"T_37fe8_row5_col3\" class=\"data row5 col3\" >-0.066</td>\n",
                            "      <td id=\"T_37fe8_row5_col4\" class=\"data row5 col4\" >-0.210</td>\n",
                            "      <td id=\"T_37fe8_row5_col5\" class=\"data row5 col5\" >1.000</td>\n",
                            "      <td id=\"T_37fe8_row5_col6\" class=\"data row5 col6\" >0.052</td>\n",
                            "      <td id=\"T_37fe8_row5_col7\" class=\"data row5 col7\" >0.191</td>\n",
                            "      <td id=\"T_37fe8_row5_col8\" class=\"data row5 col8\" >-0.047</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row6\" class=\"row_heading level0 row6\" >calculated_host_listings_count</th>\n",
                            "      <td id=\"T_37fe8_row6_col0\" class=\"data row6 col0\" >0.183</td>\n",
                            "      <td id=\"T_37fe8_row6_col1\" class=\"data row6 col1\" >-0.001</td>\n",
                            "      <td id=\"T_37fe8_row6_col2\" class=\"data row6 col2\" >0.078</td>\n",
                            "      <td id=\"T_37fe8_row6_col3\" class=\"data row6 col3\" >-0.056</td>\n",
                            "      <td id=\"T_37fe8_row6_col4\" class=\"data row6 col4\" >0.182</td>\n",
                            "      <td id=\"T_37fe8_row6_col5\" class=\"data row6 col5\" >0.052</td>\n",
                            "      <td id=\"T_37fe8_row6_col6\" class=\"data row6 col6\" >1.000</td>\n",
                            "      <td id=\"T_37fe8_row6_col7\" class=\"data row6 col7\" >0.414</td>\n",
                            "      <td id=\"T_37fe8_row6_col8\" class=\"data row6 col8\" >-0.091</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row7\" class=\"row_heading level0 row7\" >availability_365</th>\n",
                            "      <td id=\"T_37fe8_row7_col0\" class=\"data row7 col0\" >0.203</td>\n",
                            "      <td id=\"T_37fe8_row7_col1\" class=\"data row7 col1\" >-0.011</td>\n",
                            "      <td id=\"T_37fe8_row7_col2\" class=\"data row7 col2\" >0.073</td>\n",
                            "      <td id=\"T_37fe8_row7_col3\" class=\"data row7 col3\" >0.113</td>\n",
                            "      <td id=\"T_37fe8_row7_col4\" class=\"data row7 col4\" >0.157</td>\n",
                            "      <td id=\"T_37fe8_row7_col5\" class=\"data row7 col5\" >0.191</td>\n",
                            "      <td id=\"T_37fe8_row7_col6\" class=\"data row7 col6\" >0.414</td>\n",
                            "      <td id=\"T_37fe8_row7_col7\" class=\"data row7 col7\" >1.000</td>\n",
                            "      <td id=\"T_37fe8_row7_col8\" class=\"data row7 col8\" >0.097</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_37fe8_level0_row8\" class=\"row_heading level0 row8\" >precio_log</th>\n",
                            "      <td id=\"T_37fe8_row8_col0\" class=\"data row8 col0\" >-0.019</td>\n",
                            "      <td id=\"T_37fe8_row8_col1\" class=\"data row8 col1\" >0.083</td>\n",
                            "      <td id=\"T_37fe8_row8_col2\" class=\"data row8 col2\" >-0.388</td>\n",
                            "      <td id=\"T_37fe8_row8_col3\" class=\"data row8 col3\" >0.962</td>\n",
                            "      <td id=\"T_37fe8_row8_col4\" class=\"data row8 col4\" >0.042</td>\n",
                            "      <td id=\"T_37fe8_row8_col5\" class=\"data row8 col5\" >-0.047</td>\n",
                            "      <td id=\"T_37fe8_row8_col6\" class=\"data row8 col6\" >-0.091</td>\n",
                            "      <td id=\"T_37fe8_row8_col7\" class=\"data row8 col7\" >0.097</td>\n",
                            "      <td id=\"T_37fe8_row8_col8\" class=\"data row8 col8\" >1.000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "<pandas.io.formats.style.Styler at 0x7f33cd202680>"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Relaciones entre caractersticas\n",
                "\n",
                "corr = ds_new.corr()\n",
                "corr.style.background_gradient(cmap=\"coolwarm\").format(precision=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "host_id                          -0.02\n",
                            "latitude                          0.08\n",
                            "longitude                        -0.39\n",
                            "price                             0.96\n",
                            "minimum_nights                    0.04\n",
                            "number_of_reviews                -0.05\n",
                            "calculated_host_listings_count   -0.09\n",
                            "availability_365                  0.10\n",
                            "precio_log                        1.00\n",
                            "Name: precio_log, dtype: float64"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "corr.precio_log #Tiene correlaciones super bajas con el resto de las variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0     longitude\n",
                            "1         price\n",
                            "2    precio_log\n",
                            "dtype: object"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pd.Series(corr[corr.precio_log.abs() > 0.1].index)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "host_id                             1.82\n",
                            "latitude                            1.23\n",
                            "longitude                           2.79\n",
                            "price                             792.25\n",
                            "minimum_nights                      1.79\n",
                            "number_of_reviews                   1.93\n",
                            "calculated_host_listings_count      2.87\n",
                            "availability_365                    3.09\n",
                            "precio_log                        820.54\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "vif = pd.Series([variance_inflation_factor(corr.values, i) for i in range(corr.shape[1])], index= ds_new.columns)\n",
                "vif\n",
                "\n",
                "# Cmo discrimina el cdigo cuales son las variables predictoras y cuale es el objetivo?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>host_id</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>precio_log</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2787</td>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>149</td>\n",
                            "      <td>1</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>3.5</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2845</td>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>225</td>\n",
                            "      <td>1</td>\n",
                            "      <td>45.0</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>4632</td>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>150</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4869</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1</td>\n",
                            "      <td>58.5</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>7192</td>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>80</td>\n",
                            "      <td>10</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48890</th>\n",
                            "      <td>8232441</td>\n",
                            "      <td>40.68</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>70</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>9</td>\n",
                            "      <td>4.25</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48891</th>\n",
                            "      <td>6570630</td>\n",
                            "      <td>40.70</td>\n",
                            "      <td>-73.93</td>\n",
                            "      <td>40</td>\n",
                            "      <td>4</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.69</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48892</th>\n",
                            "      <td>23492952</td>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>115</td>\n",
                            "      <td>10</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>27</td>\n",
                            "      <td>4.74</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48893</th>\n",
                            "      <td>30985759</td>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>55</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>3.5</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4.01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48894</th>\n",
                            "      <td>68119814</td>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>90</td>\n",
                            "      <td>7</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>23</td>\n",
                            "      <td>4.50</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48877 rows  9 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        host_id  latitude  longitude  price  minimum_nights  \\\n",
                            "0          2787     40.65     -73.97    149               1   \n",
                            "1          2845     40.75     -73.98    225               1   \n",
                            "2          4632     40.81     -73.94    150               3   \n",
                            "3          4869     40.69     -73.96     89               1   \n",
                            "4          7192     40.80     -73.94     80              10   \n",
                            "...         ...       ...        ...    ...             ...   \n",
                            "48890   8232441     40.68     -73.95     70               2   \n",
                            "48891   6570630     40.70     -73.93     40               4   \n",
                            "48892  23492952     40.81     -73.95    115              10   \n",
                            "48893  30985759     40.76     -73.99     55               1   \n",
                            "48894  68119814     40.76     -73.99     90               7   \n",
                            "\n",
                            "       number_of_reviews  calculated_host_listings_count  availability_365  \\\n",
                            "0                    9.0                             3.5               365   \n",
                            "1                   45.0                             2.0               355   \n",
                            "2                    0.0                             1.0               365   \n",
                            "3                   58.5                             1.0               194   \n",
                            "4                    9.0                             1.0                 0   \n",
                            "...                  ...                             ...               ...   \n",
                            "48890                0.0                             2.0                 9   \n",
                            "48891                0.0                             2.0                36   \n",
                            "48892                0.0                             1.0                27   \n",
                            "48893                0.0                             3.5                 2   \n",
                            "48894                0.0                             1.0                23   \n",
                            "\n",
                            "       precio_log  \n",
                            "0            5.00  \n",
                            "1            5.42  \n",
                            "2            5.01  \n",
                            "3            4.49  \n",
                            "4            4.38  \n",
                            "...           ...  \n",
                            "48890        4.25  \n",
                            "48891        3.69  \n",
                            "48892        4.74  \n",
                            "48893        4.01  \n",
                            "48894        4.50  \n",
                            "\n",
                            "[48877 rows x 9 columns]"
                        ]
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Me carge \"price\" con un Inplace True\n",
                "ds_new"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Divido el DF en variables de entrenamiento y testeo con train_test_split\n",
                "\n",
                "x= ds_new.drop([\"precio_log\"], axis = 1)\n",
                "y = ds_new[\"precio_log\"]\n",
                "\n",
                "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Feature: price, Importance: 97.80453443527222\n",
                        "Feature: minimum_nights, Importance: 0.4025622271001339\n",
                        "Feature: calculated_host_listings_count, Importance: 0.32905545085668564\n",
                        "Feature: number_of_reviews, Importance: 0.3180810948833823\n",
                        "Feature: longitude, Importance: 0.2969633089378476\n",
                        "Feature: latitude, Importance: 0.2957139629870653\n",
                        "Feature: availability_365, Importance: 0.2862907946109772\n",
                        "Feature: host_id, Importance: 0.2668021945282817\n"
                    ]
                }
            ],
            "source": [
                "# Vamos a usar un mtodo embebido que nos informe de la importancia de las caractersticas\n",
                "# Crea un modelo XGBoost Regressor\n",
                "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
                "\n",
                "# Entrena el modelo en los datos de entrenamiento\n",
                "model.fit(x_train, y_train)\n",
                "\n",
                "# Calcula la importancia de las caractersticas\n",
                "feature_importances = model.feature_importances_\n",
                "\n",
                "# Asocia las importancias con los nombres de las caractersticas\n",
                "feature_names = x.columns\n",
                "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
                "\n",
                "# Ordena las caractersticas por importancia (de mayor a menor)\n",
                "sorted_feature_importance = dict(sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True))\n",
                "\n",
                "# Imprime la importancia de las caractersticas (nmero adimensional, las caractersticas se comparan entre s en trminos de su contribucin relativa a la prediccin)\n",
                "for feature, importance in sorted_feature_importance.items():\n",
                "    print(f'Feature: {feature}, Importance: {importance*100}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Bsqueda de Variables con baja correlacin y baja importancia:\n",
                "\n",
                "def get_vars_to_delete(d_imp, corr, imp_cut=0.005, corr_cut=0.1):\n",
                "  ls_vars_low_corr = corr[corr.precio_log.abs()<=corr_cut].index\n",
                "  return [var for var in ls_vars_low_corr if d_imp[var]<=imp_cut]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['host_id',\n",
                            " 'latitude',\n",
                            " 'minimum_nights',\n",
                            " 'number_of_reviews',\n",
                            " 'calculated_host_listings_count',\n",
                            " 'availability_365']"
                        ]
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "vars_to_drop = get_vars_to_delete(sorted_feature_importance, corr, imp_cut=0.01, corr_cut=0.15)\n",
                "vars_to_drop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>host_id</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>count</th>\n",
                            "      <td>3.67e+04</td>\n",
                            "      <td>36657.00</td>\n",
                            "      <td>36657.00</td>\n",
                            "      <td>36657.00</td>\n",
                            "      <td>36657.00</td>\n",
                            "      <td>36657.00</td>\n",
                            "      <td>36657.00</td>\n",
                            "      <td>36657.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>mean</th>\n",
                            "      <td>6.74e+07</td>\n",
                            "      <td>40.73</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>133.21</td>\n",
                            "      <td>3.82</td>\n",
                            "      <td>15.73</td>\n",
                            "      <td>1.61</td>\n",
                            "      <td>112.81</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>std</th>\n",
                            "      <td>7.79e+07</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>0.04</td>\n",
                            "      <td>83.33</td>\n",
                            "      <td>3.32</td>\n",
                            "      <td>20.38</td>\n",
                            "      <td>0.95</td>\n",
                            "      <td>131.44</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>min</th>\n",
                            "      <td>2.57e+03</td>\n",
                            "      <td>40.58</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>10.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25%</th>\n",
                            "      <td>7.83e+06</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>69.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50%</th>\n",
                            "      <td>3.11e+07</td>\n",
                            "      <td>40.72</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>109.00</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>46.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75%</th>\n",
                            "      <td>1.07e+08</td>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>175.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>24.00</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>227.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>max</th>\n",
                            "      <td>2.57e+08</td>\n",
                            "      <td>40.87</td>\n",
                            "      <td>-73.87</td>\n",
                            "      <td>334.00</td>\n",
                            "      <td>11.00</td>\n",
                            "      <td>58.50</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>365.00</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        host_id  latitude  longitude     price  minimum_nights  \\\n",
                            "count  3.67e+04  36657.00   36657.00  36657.00        36657.00   \n",
                            "mean   6.74e+07     40.73     -73.95    133.21            3.82   \n",
                            "std    7.79e+07      0.05       0.04     83.33            3.32   \n",
                            "min    2.57e+03     40.58     -74.05     10.00            1.00   \n",
                            "25%    7.83e+06     40.69     -73.98     69.00            1.00   \n",
                            "50%    3.11e+07     40.72     -73.96    109.00            2.00   \n",
                            "75%    1.07e+08     40.76     -73.94    175.00            5.00   \n",
                            "max    2.57e+08     40.87     -73.87    334.00           11.00   \n",
                            "\n",
                            "       number_of_reviews  calculated_host_listings_count  availability_365  \n",
                            "count           36657.00                        36657.00          36657.00  \n",
                            "mean               15.73                            1.61            112.81  \n",
                            "std                20.38                            0.95            131.44  \n",
                            "min                 0.00                            1.00              0.00  \n",
                            "25%                 1.00                            1.00              0.00  \n",
                            "50%                 5.00                            1.00             46.00  \n",
                            "75%                24.00                            2.00            227.00  \n",
                            "max                58.50                            3.50            365.00  "
                        ]
                    },
                    "execution_count": 43,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "x_train.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "X TRAIN -->  Mnimo: 0.0 - Mximo: 1.0\n",
                        "X TEST -->   Mnimo: -5.178130371166611e-07 - Mximo: 1.0\n"
                    ]
                }
            ],
            "source": [
                "#Escalado de Datos\n",
                "\n",
                "scaler = MinMaxScaler().fit(x_train) # Es importante ajustar el escalador usando SIEMPRE los datos de entrenamiento.\n",
                "x_train_sc = scaler.transform(x_train)\n",
                "x_test_sc = scaler.transform(x_test)\n",
                "\n",
                "print(f\"X TRAIN -->  Mnimo: {x_train_sc.min()} - Mximo: {x_test_sc.max()}\")\n",
                "\n",
                "print(f\"X TEST -->   Mnimo: {x_test_sc.min()} - Mximo: {x_test_sc.max()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "36657\n",
                        "(12220, 8)\n"
                    ]
                }
            ],
            "source": [
                "type(x_test_sc)\n",
                "\n",
                "x_train_sc = pd.DataFrame(x_train_sc, columns = x_train.columns)\n",
                "\n",
                "x_test_sc = pd.DataFrame(x_test_sc, columns = x_test.columns)\n",
                "\n",
                "print(y_train.shape[0])\n",
                "\n",
                "print(x_test.shape)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "No puedo instalar Lazy Predict, por ende voy a usar el algoritmo de LGBMRegressor, al igual que en la clase."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003264 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003408 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002796 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003218 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002934 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003076 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002907 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002382 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003072 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004826 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000817 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002999 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003289 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002794 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007673 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003237 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002943 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003122 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002921 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002973 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002465 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003009 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003101 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002716 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002930 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003002 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000768 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002594 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007041 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
                        "60 fits failed out of a total of 250.\n",
                        "The score on these train-test partitions for these parameters will be set to nan.\n",
                        "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
                        "\n",
                        "Below are more details about the failures:\n",
                        "--------------------------------------------------------------------------------\n",
                        "60 fits failed with the following error:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/home/vscode/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
                        "    estimator.fit(X_train, y_train, **fit_params)\n",
                        "  File \"/home/vscode/.local/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1092, in fit\n",
                        "    super().fit(\n",
                        "  File \"/home/vscode/.local/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 885, in fit\n",
                        "    self._Booster = train(\n",
                        "  File \"/home/vscode/.local/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
                        "    booster = Booster(params=params, train_set=train_set)\n",
                        "  File \"/home/vscode/.local/lib/python3.10/site-packages/lightgbm/basic.py\", line 3437, in __init__\n",
                        "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
                        "  File \"/home/vscode/.local/lib/python3.10/site-packages/lightgbm/basic.py\", line 263, in _safe_call\n",
                        "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
                        "lightgbm.basic.LightGBMError: Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
                        "\n",
                        "\n",
                        "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-0.60847956 -0.22753775 -0.07066544 -1.98711657 -0.06483039 -0.22758067\n",
                        " -0.06543779 -0.07028884 -1.24945826 -2.17922014         nan -1.24941029\n",
                        "         nan -0.07942369 -1.98717301 -0.07772299         nan         nan\n",
                        " -1.98710663         nan -0.07074156         nan -0.07100263 -0.60847956\n",
                        " -2.17921987 -1.24945826 -0.06381799 -2.17921987 -0.07914064 -0.07891825\n",
                        "         nan -0.07082437 -2.17922014 -2.17922014         nan         nan\n",
                        "         nan -0.07914064 -0.07813494 -0.06393328 -1.24940037 -0.06573327\n",
                        "         nan -0.3855656  -0.38670156 -0.06498882         nan -0.06684252\n",
                        " -1.24945247 -0.06216331]\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1293\n",
                        "[LightGBM] [Info] Number of data points in the train set: 36657, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722877\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {\n",
                            "  /* Definition of color scheme common for light and dark mode */\n",
                            "  --sklearn-color-text: black;\n",
                            "  --sklearn-color-line: gray;\n",
                            "  /* Definition of color scheme for unfitted estimators */\n",
                            "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                            "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                            "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                            "  --sklearn-color-unfitted-level-3: chocolate;\n",
                            "  /* Definition of color scheme for fitted estimators */\n",
                            "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                            "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                            "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                            "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                            "\n",
                            "  /* Specific color for light theme */\n",
                            "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                            "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-icon: #696969;\n",
                            "\n",
                            "  @media (prefers-color-scheme: dark) {\n",
                            "    /* Redefinition of color scheme for dark theme */\n",
                            "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                            "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-icon: #878787;\n",
                            "  }\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 pre {\n",
                            "  padding: 0;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-hidden--visually {\n",
                            "  border: 0;\n",
                            "  clip: rect(1px 1px 1px 1px);\n",
                            "  clip: rect(1px, 1px, 1px, 1px);\n",
                            "  height: 1px;\n",
                            "  margin: -1px;\n",
                            "  overflow: hidden;\n",
                            "  padding: 0;\n",
                            "  position: absolute;\n",
                            "  width: 1px;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-dashed-wrapped {\n",
                            "  border: 1px dashed var(--sklearn-color-line);\n",
                            "  margin: 0 0.4em 0.5em 0.4em;\n",
                            "  box-sizing: border-box;\n",
                            "  padding-bottom: 0.4em;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-container {\n",
                            "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                            "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                            "     so we also need the `!important` here to be able to override the\n",
                            "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                            "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                            "  display: inline-block !important;\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-text-repr-fallback {\n",
                            "  display: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-parallel-item,\n",
                            "div.sk-serial,\n",
                            "div.sk-item {\n",
                            "  /* draw centered vertical line to link estimators */\n",
                            "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                            "  background-size: 2px 100%;\n",
                            "  background-repeat: no-repeat;\n",
                            "  background-position: center center;\n",
                            "}\n",
                            "\n",
                            "/* Parallel-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item::after {\n",
                            "  content: \"\";\n",
                            "  width: 100%;\n",
                            "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                            "  flex-grow: 1;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel {\n",
                            "  display: flex;\n",
                            "  align-items: stretch;\n",
                            "  justify-content: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
                            "  align-self: flex-end;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
                            "  align-self: flex-start;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
                            "  width: 0;\n",
                            "}\n",
                            "\n",
                            "/* Serial-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-serial {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "  align-items: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  padding-right: 1em;\n",
                            "  padding-left: 1em;\n",
                            "}\n",
                            "\n",
                            "\n",
                            "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                            "clickable and can be expanded/collapsed.\n",
                            "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                            "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                            "*/\n",
                            "\n",
                            "/* Pipeline and ColumnTransformer style (default) */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable {\n",
                            "  /* Default theme specific background. It is overwritten whether we have a\n",
                            "  specific estimator or a Pipeline/ColumnTransformer */\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable label */\n",
                            "#sk-container-id-1 label.sk-toggleable__label {\n",
                            "  cursor: pointer;\n",
                            "  display: block;\n",
                            "  width: 100%;\n",
                            "  margin-bottom: 0;\n",
                            "  padding: 0.5em;\n",
                            "  box-sizing: border-box;\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
                            "  /* Arrow on the left of the label */\n",
                            "  content: \"\";\n",
                            "  float: left;\n",
                            "  margin-right: 0.25em;\n",
                            "  color: var(--sklearn-color-icon);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable content - dropdown */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content {\n",
                            "  max-height: 0;\n",
                            "  max-width: 0;\n",
                            "  overflow: hidden;\n",
                            "  text-align: left;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content pre {\n",
                            "  margin: 0.2em;\n",
                            "  border-radius: 0.25em;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                            "  /* Expand drop-down */\n",
                            "  max-height: 200px;\n",
                            "  max-width: 100%;\n",
                            "  overflow: auto;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                            "  content: \"\";\n",
                            "}\n",
                            "\n",
                            "/* Pipeline/ColumnTransformer-specific style */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific style */\n",
                            "\n",
                            "/* Colorize estimator box */\n",
                            "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
                            "#sk-container-id-1 div.sk-label label {\n",
                            "  /* The background is the default theme color */\n",
                            "  color: var(--sklearn-color-text-on-default-background);\n",
                            "}\n",
                            "\n",
                            "/* On hover, darken the color of the background */\n",
                            "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Label box, darken color on hover, fitted */\n",
                            "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator label */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label label {\n",
                            "  font-family: monospace;\n",
                            "  font-weight: bold;\n",
                            "  display: inline-block;\n",
                            "  line-height: 1.2em;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label-container {\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific */\n",
                            "#sk-container-id-1 div.sk-estimator {\n",
                            "  font-family: monospace;\n",
                            "  border: 1px dotted var(--sklearn-color-border-box);\n",
                            "  border-radius: 0.25em;\n",
                            "  box-sizing: border-box;\n",
                            "  margin-bottom: 0.5em;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "/* on hover */\n",
                            "#sk-container-id-1 div.sk-estimator:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                            "\n",
                            "/* Common style for \"i\" and \"?\" */\n",
                            "\n",
                            ".sk-estimator-doc-link,\n",
                            "a:link.sk-estimator-doc-link,\n",
                            "a:visited.sk-estimator-doc-link {\n",
                            "  float: right;\n",
                            "  font-size: smaller;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1em;\n",
                            "  height: 1em;\n",
                            "  width: 1em;\n",
                            "  text-decoration: none !important;\n",
                            "  margin-left: 1ex;\n",
                            "  /* unfitted */\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted,\n",
                            "a:link.sk-estimator-doc-link.fitted,\n",
                            "a:visited.sk-estimator-doc-link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "/* Span, style for the box shown on hovering the info icon */\n",
                            ".sk-estimator-doc-link span {\n",
                            "  display: none;\n",
                            "  z-index: 9999;\n",
                            "  position: relative;\n",
                            "  font-weight: normal;\n",
                            "  right: .2ex;\n",
                            "  padding: .5ex;\n",
                            "  margin: .5ex;\n",
                            "  width: min-content;\n",
                            "  min-width: 20ex;\n",
                            "  max-width: 50ex;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  box-shadow: 2pt 2pt 4pt #999;\n",
                            "  /* unfitted */\n",
                            "  background: var(--sklearn-color-unfitted-level-0);\n",
                            "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted span {\n",
                            "  /* fitted */\n",
                            "  background: var(--sklearn-color-fitted-level-0);\n",
                            "  border: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link:hover span {\n",
                            "  display: block;\n",
                            "}\n",
                            "\n",
                            "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link {\n",
                            "  float: right;\n",
                            "  font-size: 1rem;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1rem;\n",
                            "  height: 1rem;\n",
                            "  width: 1rem;\n",
                            "  text-decoration: none;\n",
                            "  /* unfitted */\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "#sk-container-id-1 a.estimator_doc_link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=50, n_jobs=1,\n",
                            "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;, &#x27;rf&#x27;],\n",
                            "                                        &#x27;learning_rate&#x27;: array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
                            "                                        &#x27;max_depth&#x27;: array([ 20,  50,  80, 110, 140, 170, 200, 230]),\n",
                            "                                        &#x27;num_leaves&#x27;: array([ 20,  50,  80, 110, 140, 170, 200, 230])},\n",
                            "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
                            "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=50, n_jobs=1,\n",
                            "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;, &#x27;rf&#x27;],\n",
                            "                                        &#x27;learning_rate&#x27;: array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
                            "                                        &#x27;max_depth&#x27;: array([ 20,  50,  80, 110, 140, 170, 200, 230]),\n",
                            "                                        &#x27;num_leaves&#x27;: array([ 20,  50,  80, 110, 140, 170, 200, 230])},\n",
                            "                   random_state=10, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
                            "                   verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=50, n_jobs=1,\n",
                            "                   param_distributions={'boosting_type': ['gbdt', 'dart', 'rf'],\n",
                            "                                        'learning_rate': array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
                            "                                        'max_depth': array([ 20,  50,  80, 110, 140, 170, 200, 230]),\n",
                            "                                        'num_leaves': array([ 20,  50,  80, 110, 140, 170, 200, 230])},\n",
                            "                   random_state=10, scoring='neg_root_mean_squared_error',\n",
                            "                   verbose=1)"
                        ]
                    },
                    "execution_count": 46,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Haremos una Bsqeuda Aleatoria para buscar la mejor combinacin de Hiperparmetros (optimizacin) \n",
                "# Randomized Search CV selecciona aleatoriamente combinaciones de valores para los hiperparmetros y evala su rendimiento.\n",
                "\n",
                "# 1er Paso: llamar al algoritmo.\n",
                "model = lgb.LGBMRegressor()\n",
                "\n",
                "# 2do Paso: definir el espacio de bsqueda con un diccionario. \n",
                "param_dic = {'boosting_type': ['gbdt','dart','rf'],\n",
                "              'num_leaves': np.arange(20, 250, 30),\n",
                "              'max_depth':np.arange(20, 250, 30),\n",
                "              'learning_rate':np.logspace(-3,0,5)}\n",
                "\n",
                "# 3er Paso: ejecutar la Bsqueda Aleatora, pasando los Datos de Entrenamiento Escalados: \n",
                "random_search = RandomizedSearchCV(estimator= model, param_distributions=param_dic, n_iter=50, cv=5, random_state=10, n_jobs=1, scoring='neg_root_mean_squared_error', verbose=1)\n",
                "random_search.fit(x_train_sc, y_train)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mejores hiperparmetros encontrados:\n",
                        "{'num_leaves': 20, 'max_depth': 20, 'learning_rate': 0.1778279410038923, 'boosting_type': 'gbdt'}\n",
                        "Mejor puntuacin (  en el conjunto de prueba:\n",
                        "0.06216330964892689\n"
                    ]
                }
            ],
            "source": [
                "# Mostramos los mejores hiperparmetros encontrados\n",
                "print(\"Mejores hiperparmetros encontrados:\")\n",
                "print(random_search.best_params_)\n",
                "\n",
                "# Mostramos el rendimiento del mejor modelo\n",
                "print(\"Mejor puntuacin (  en el conjunto de prueba:\")\n",
                "print(-1*random_search.best_score_)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003088 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002275 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003728 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003264 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003174 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003274 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002500 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003372 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003229 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003621 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003304 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002913 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003311 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002998 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003177 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003081 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003136 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003773 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003155 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=21; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003009 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003145 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=21; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002980 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004519 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003039 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003262 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=5; total time=   0.1s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003080 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003192 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=29; total time=   0.3s[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003070 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003193 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003032 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009082 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003040 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003219 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003158 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003532 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002965 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003706 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003201 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005194 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003031 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003271 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003443 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002915 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008439 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003795 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003282 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003175 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003406 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003013 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003245 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003162 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003254 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002965 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002976 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005775 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003090 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003142 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=5; total time=   0.1s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003327 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000653 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003171 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003300 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002945 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003160 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004991 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003167 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004298 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003720 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=21; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=21; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003013 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003201 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003086 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007261 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=5; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=5; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003178 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003317 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=5; total time=   0.1s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003137 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003011 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=29, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=29, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002922 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003137 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=29, num_leaves=21; total time=   0.2s[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=29, num_leaves=21; total time=   0.3s\n",
                        "\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=29, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005428 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003169 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=21; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003415 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003783 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=21; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004195 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=21; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002815 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003003 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003238 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002986 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003318 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003229 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=29, num_leaves=5; total time=   0.1s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003045 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003349 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=21; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003163 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002904 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005295 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003410 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003264 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003658 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=13, num_leaves=13; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003051 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003269 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003496 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003993 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003036 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002995 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003214 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011052 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003916 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002992 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=29; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002958 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003352 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003311 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005104 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=5; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002955 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003304 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003030 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002960 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003328 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002871 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003284 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=21, num_leaves=5; total time=   0.1s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003328 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003070 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=21, num_leaves=5; total time=   0.1s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003137 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003173 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003015 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003732 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002879 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004039 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004325 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004717 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003066 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=21, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003096 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003205 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002959 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003327 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003637 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=13, num_leaves=5; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003136 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003082 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003266 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003109 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003360 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003303 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=29; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003144 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003125 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=5, num_leaves=29; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003116 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003234 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002979 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011096 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=21, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003533 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003336 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003894 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=5, num_leaves=29; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003052 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004370 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002960 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003284 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003046 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003218 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003361 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003418 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=13, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003079 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003759 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002975 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=13, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005163 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003777 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=21; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003054 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003322 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003387 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003415 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003132 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004691 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003125 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002929 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003273 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003117 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=5; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=5; total time=   0.1s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003084 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006928 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=13; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003145 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=13; total time=   0.2s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=13; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=13; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003093 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003195 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=29, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=29, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003258 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003227 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=29, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=29, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.09, max_depth=29, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004295 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005941 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004207 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004425 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=5, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003118 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003228 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002987 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=29; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=29; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=5, num_leaves=29; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003216 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003320 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=21; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=21; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003057 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003155 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=21; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=5, num_leaves=21; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003803 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.720307[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004021 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29325, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722292\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003028 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723343\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003138 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 1294\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.723729\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=29; total time=   0.3s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=29; total time=   0.3s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1292\n",
                        "[LightGBM] [Info] Number of data points in the train set: 29326, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.724715\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.12, max_depth=29, num_leaves=29; total time=   0.2s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 1293\n",
                        "[LightGBM] [Info] Number of data points in the train set: 36657, number of used features: 8\n",
                        "[LightGBM] [Info] Start training from score 4.722877\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-2 {\n",
                            "  /* Definition of color scheme common for light and dark mode */\n",
                            "  --sklearn-color-text: black;\n",
                            "  --sklearn-color-line: gray;\n",
                            "  /* Definition of color scheme for unfitted estimators */\n",
                            "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                            "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                            "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                            "  --sklearn-color-unfitted-level-3: chocolate;\n",
                            "  /* Definition of color scheme for fitted estimators */\n",
                            "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                            "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                            "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                            "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                            "\n",
                            "  /* Specific color for light theme */\n",
                            "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                            "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-icon: #696969;\n",
                            "\n",
                            "  @media (prefers-color-scheme: dark) {\n",
                            "    /* Redefinition of color scheme for dark theme */\n",
                            "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                            "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-icon: #878787;\n",
                            "  }\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 pre {\n",
                            "  padding: 0;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-hidden--visually {\n",
                            "  border: 0;\n",
                            "  clip: rect(1px 1px 1px 1px);\n",
                            "  clip: rect(1px, 1px, 1px, 1px);\n",
                            "  height: 1px;\n",
                            "  margin: -1px;\n",
                            "  overflow: hidden;\n",
                            "  padding: 0;\n",
                            "  position: absolute;\n",
                            "  width: 1px;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-dashed-wrapped {\n",
                            "  border: 1px dashed var(--sklearn-color-line);\n",
                            "  margin: 0 0.4em 0.5em 0.4em;\n",
                            "  box-sizing: border-box;\n",
                            "  padding-bottom: 0.4em;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-container {\n",
                            "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                            "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                            "     so we also need the `!important` here to be able to override the\n",
                            "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                            "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                            "  display: inline-block !important;\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-text-repr-fallback {\n",
                            "  display: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-parallel-item,\n",
                            "div.sk-serial,\n",
                            "div.sk-item {\n",
                            "  /* draw centered vertical line to link estimators */\n",
                            "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                            "  background-size: 2px 100%;\n",
                            "  background-repeat: no-repeat;\n",
                            "  background-position: center center;\n",
                            "}\n",
                            "\n",
                            "/* Parallel-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item::after {\n",
                            "  content: \"\";\n",
                            "  width: 100%;\n",
                            "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                            "  flex-grow: 1;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel {\n",
                            "  display: flex;\n",
                            "  align-items: stretch;\n",
                            "  justify-content: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
                            "  align-self: flex-end;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
                            "  align-self: flex-start;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
                            "  width: 0;\n",
                            "}\n",
                            "\n",
                            "/* Serial-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-serial {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "  align-items: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  padding-right: 1em;\n",
                            "  padding-left: 1em;\n",
                            "}\n",
                            "\n",
                            "\n",
                            "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                            "clickable and can be expanded/collapsed.\n",
                            "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                            "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                            "*/\n",
                            "\n",
                            "/* Pipeline and ColumnTransformer style (default) */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable {\n",
                            "  /* Default theme specific background. It is overwritten whether we have a\n",
                            "  specific estimator or a Pipeline/ColumnTransformer */\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable label */\n",
                            "#sk-container-id-2 label.sk-toggleable__label {\n",
                            "  cursor: pointer;\n",
                            "  display: block;\n",
                            "  width: 100%;\n",
                            "  margin-bottom: 0;\n",
                            "  padding: 0.5em;\n",
                            "  box-sizing: border-box;\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
                            "  /* Arrow on the left of the label */\n",
                            "  content: \"\";\n",
                            "  float: left;\n",
                            "  margin-right: 0.25em;\n",
                            "  color: var(--sklearn-color-icon);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable content - dropdown */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content {\n",
                            "  max-height: 0;\n",
                            "  max-width: 0;\n",
                            "  overflow: hidden;\n",
                            "  text-align: left;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content pre {\n",
                            "  margin: 0.2em;\n",
                            "  border-radius: 0.25em;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                            "  /* Expand drop-down */\n",
                            "  max-height: 200px;\n",
                            "  max-width: 100%;\n",
                            "  overflow: auto;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                            "  content: \"\";\n",
                            "}\n",
                            "\n",
                            "/* Pipeline/ColumnTransformer-specific style */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific style */\n",
                            "\n",
                            "/* Colorize estimator box */\n",
                            "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
                            "#sk-container-id-2 div.sk-label label {\n",
                            "  /* The background is the default theme color */\n",
                            "  color: var(--sklearn-color-text-on-default-background);\n",
                            "}\n",
                            "\n",
                            "/* On hover, darken the color of the background */\n",
                            "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Label box, darken color on hover, fitted */\n",
                            "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator label */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label label {\n",
                            "  font-family: monospace;\n",
                            "  font-weight: bold;\n",
                            "  display: inline-block;\n",
                            "  line-height: 1.2em;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label-container {\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific */\n",
                            "#sk-container-id-2 div.sk-estimator {\n",
                            "  font-family: monospace;\n",
                            "  border: 1px dotted var(--sklearn-color-border-box);\n",
                            "  border-radius: 0.25em;\n",
                            "  box-sizing: border-box;\n",
                            "  margin-bottom: 0.5em;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "/* on hover */\n",
                            "#sk-container-id-2 div.sk-estimator:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                            "\n",
                            "/* Common style for \"i\" and \"?\" */\n",
                            "\n",
                            ".sk-estimator-doc-link,\n",
                            "a:link.sk-estimator-doc-link,\n",
                            "a:visited.sk-estimator-doc-link {\n",
                            "  float: right;\n",
                            "  font-size: smaller;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1em;\n",
                            "  height: 1em;\n",
                            "  width: 1em;\n",
                            "  text-decoration: none !important;\n",
                            "  margin-left: 1ex;\n",
                            "  /* unfitted */\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted,\n",
                            "a:link.sk-estimator-doc-link.fitted,\n",
                            "a:visited.sk-estimator-doc-link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "/* Span, style for the box shown on hovering the info icon */\n",
                            ".sk-estimator-doc-link span {\n",
                            "  display: none;\n",
                            "  z-index: 9999;\n",
                            "  position: relative;\n",
                            "  font-weight: normal;\n",
                            "  right: .2ex;\n",
                            "  padding: .5ex;\n",
                            "  margin: .5ex;\n",
                            "  width: min-content;\n",
                            "  min-width: 20ex;\n",
                            "  max-width: 50ex;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  box-shadow: 2pt 2pt 4pt #999;\n",
                            "  /* unfitted */\n",
                            "  background: var(--sklearn-color-unfitted-level-0);\n",
                            "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted span {\n",
                            "  /* fitted */\n",
                            "  background: var(--sklearn-color-fitted-level-0);\n",
                            "  border: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link:hover span {\n",
                            "  display: block;\n",
                            "}\n",
                            "\n",
                            "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link {\n",
                            "  float: right;\n",
                            "  font-size: 1rem;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1rem;\n",
                            "  height: 1rem;\n",
                            "  width: 1rem;\n",
                            "  text-decoration: none;\n",
                            "  /* unfitted */\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "#sk-container-id-2 a.estimator_doc_link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
                            "              scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
                            "              search_spaces={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
                            "                             &#x27;learning_rate&#x27;: [0.09, 0.12, 0.15, 0.17, 0.2],\n",
                            "                             &#x27;max_depth&#x27;: array([ 5, 13, 21, 29]),\n",
                            "                             &#x27;num_leaves&#x27;: array([ 5, 13, 21, 29])},\n",
                            "              verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
                            "              scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
                            "              search_spaces={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
                            "                             &#x27;learning_rate&#x27;: [0.09, 0.12, 0.15, 0.17, 0.2],\n",
                            "                             &#x27;max_depth&#x27;: array([ 5, 13, 21, 29]),\n",
                            "                             &#x27;num_leaves&#x27;: array([ 5, 13, 21, 29])},\n",
                            "              verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
                            "              scoring='neg_root_mean_squared_error',\n",
                            "              search_spaces={'boosting_type': ['gbdt'],\n",
                            "                             'learning_rate': [0.09, 0.12, 0.15, 0.17, 0.2],\n",
                            "                             'max_depth': array([ 5, 13, 21, 29]),\n",
                            "                             'num_leaves': array([ 5, 13, 21, 29])},\n",
                            "              verbose=2)"
                        ]
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Luego de la bsqueda aleatoria, hacemos una bsqeuda ms especfica con los HiperParmetros obtenidos con RandomizedSearchCV\n",
                "# Se refina el Espacio de Bsqueda sen los resultados obtenidos.\n",
                "#Bsqueda Centrada a travs de Bsqueda Bayesiana:  \n",
                "\n",
                "# 1er Paso: llamar al algoritmo.\n",
                "model = lgb.LGBMRegressor()\n",
                "\n",
                "# 2do Paso: definir el espacio de bsqueda con un diccionario (teniendo en cuenta los HP obtenidos con .best_para)\n",
                "param_dic = {'boosting_type': ['gbdt'],\n",
                "              'num_leaves': np.arange(5, 30, 8),\n",
                "              'max_depth':np.arange(5, 30, 8),\n",
                "              'learning_rate':[0.09, 0.12 ,0.15,0.17,0.2,]}\n",
                "\n",
                "# 3er Paso: ejecutar la Bsqueda Aleatora, pasando los Datos de Entrenamiento Escalados: \n",
                "bay_search = BayesSearchCV(model,\n",
                "    param_dic,\n",
                "    n_iter=50,  \n",
                "    cv=5,       \n",
                "    n_jobs=-1,\n",
                "    random_state=42,\n",
                "    scoring='neg_root_mean_squared_error',  # Mtrica a optimizar\n",
                "    verbose=2)\n",
                "\n",
                "bay_search.fit(x_train_sc, y_train)\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mejores hiperparmetros encontrados:\n",
                        "OrderedDict([('boosting_type', 'gbdt'), ('learning_rate', 0.12), ('max_depth', 21), ('num_leaves', 13)])\n",
                        "Mejor puntuacin (RMSE) en el conjunto de prueba:\n",
                        "0.061265589230971904\n"
                    ]
                }
            ],
            "source": [
                "print(\"Mejores hiperparmetros encontrados:\")\n",
                "print(bay_search.best_params_)\n",
                "\n",
                "# Mostramos el rendimiento del mejor modelo\n",
                "print(\"Mejor puntuacin (RMSE) en el conjunto de prueba:\")\n",
                "print(-1*bay_search.best_score_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = bay_search.best_estimator_\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
